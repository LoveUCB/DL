{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降\n",
    "- $x' = x - \\dfrac{dy}{dx}$ 梯度迭代\n",
    "- learning rate：导数乘上一个值——新手一般设置0.001\n",
    "## 线性回归\n",
    "- 线性回归高斯噪声\n",
    "- 损失函数，求解损失函数最小值\n",
    "$$\n",
    "loss = (w*x_i + b - y_i) ^ 2\n",
    "$$\n",
    "$$\n",
    "w' = w - lr * \\dfrac{dloss}{dw}\n",
    "$$\n",
    "- 逻辑回归 —— 激活函数将范围压缩到[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 计算损失函数\n",
    "def loss_function(b, w, points):\n",
    "    totalError = 0\n",
    "    for i in range(len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        totalError += (y - (w * x + b)) ** 2\n",
    "    return totalError / float(len(points))\n",
    "\n",
    "# 计算梯度下降\n",
    "def step_gradient(b_current, w_current, points, learningRate):\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += -(2/N) * (y - ((w_current) + b_current))\n",
    "        w_gradient += -(2/N) * x * (y - ((w_current)*x) + b_current)\n",
    "    new_b = b_current - (learningRate * b_gradient)\n",
    "    new_m = w_current - (learningRate * w_gradient)\n",
    "    return [new_b, new_m]    \n",
    "# 迭代100次\n",
    "def runner(points, starting_b, starting_m, learningRate, num_interactions):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_interactions):\n",
    "        b, m = step_gradient(b, m, np.array(points), learningRate)\n",
    "    return [b, m]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
